{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b559fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sqlalchemy\n",
    "# !pip install psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c99c96b",
   "metadata": {},
   "source": [
    "### Verificando duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62701ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\digital college\\DA18\\PYTHON\\Projeto_Unidade_3\\_4_Etapa_ETL\\merge_csv\\merge_colunas_produtos_csv.csv\")\n",
    "duplicados = df.duplicated(subset=[\"Produto/Unidade\"]).sum()\n",
    "print(duplicados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f59cf1",
   "metadata": {},
   "source": [
    "### INSERINDO PRODUTOS NO BANCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3299ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Conexão estabelecida com sucesso\n",
      "✓ Conexão encerrada com sucesso\n",
      "Sucesso!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import psycopg2\n",
    "# Adiciona o caminho absoluto da pasta _9_funcoes ao Python\n",
    "caminho_funcoes = r'C:\\digital college\\DA18\\PYTHON\\Projeto_Unidade_3\\_9_funcoes'\n",
    "sys.path.append(caminho_funcoes)\n",
    "\n",
    "# Agora os imports devem funcionar\n",
    "from conectar_banco import conectar_banco\n",
    "from atualizar_macrogrupo import atualizar_macrogrupo\n",
    "from fechar_conexao import fechar_conexao\n",
    "\n",
    "def importar_produtos():\n",
    "    conexao, cursor = conectar_banco()\n",
    "    if not conexao:\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        with open(r\"C:\\digital college\\DA18\\PYTHON\\Projeto_Unidade_3\\_4_Etapa_ETL\\merge_csv\\merge_colunas_produtos_csv.csv\", encoding=\"utf-8\") as arquivo:\n",
    "            for linha in csv.reader(arquivo):\n",
    "                if linha:\n",
    "                    cursor.execute(\"INSERT INTO datawarehouse.dim_produtos (prod_und) VALUES (%s)\", \n",
    "                                 (linha[0].strip(),))\n",
    "        conexao.commit()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Erro: {e}\")\n",
    "        conexao.rollback()\n",
    "        return False\n",
    "    finally:\n",
    "        fechar_conexao(conexao, cursor)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if importar_produtos():\n",
    "        print(\"Sucesso!\")\n",
    "    else:\n",
    "        print(\"Falha na importação\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4c7411",
   "metadata": {},
   "source": [
    "### INSERINDO NIVEL DE COMERCIALIZAÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5553fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import psycopg2\n",
    "# Adiciona o caminho absoluto da pasta _9_funcoes ao Python\n",
    "caminho_funcoes = r'C:\\digital college\\DA18\\PYTHON\\Projeto_Unidade_3\\_9_funcoes'\n",
    "sys.path.append(caminho_funcoes)\n",
    "\n",
    "# Agora os imports devem funcionar\n",
    "from conectar_banco import conectar_banco\n",
    "from atualizar_macrogrupo import atualizar_macrogrupo\n",
    "from fechar_conexao import fechar_conexao\n",
    "\n",
    "# Abrir o CSV\n",
    "def importar_nivel_comercializacao():\n",
    "    conexao, cursor = conectar_banco()\n",
    "    if not conexao:\n",
    "        return False\n",
    "    try:\n",
    "        with open(r\"C:\\digital college\\DA18\\PYTHON\\Projeto_Unidade_3\\_4_Etapa_ETL\\merge_csv\\merge_colunas_nivel_comercializacao_csv.csv\", encoding=\"utf-8\") as arquivo_csv:\n",
    "            leitor = csv.reader(arquivo_csv)\n",
    "\n",
    "            next(leitor)  # Ignora o cabeçalho\n",
    "\n",
    "            for linha in leitor:\n",
    "                if linha:  # ignora linhas vazias\n",
    "                    tipo_de_comercializacao = linha[0].strip()\n",
    "                    cursor.execute(\"INSERT INTO datawarehouse.dim_nivel_comercializacao (tipo_de_comercializacao) VALUES (%s)\", (tipo_de_comercializacao,))\n",
    "        conexao.commit()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Erro: {e}\")\n",
    "        conexao.rollback()\n",
    "        return False\n",
    "    finally:\n",
    "        fechar_conexao(conexao, cursor)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if importar_nivel_comercializacao():\n",
    "        print(\"Sucesso!\")\n",
    "    else:\n",
    "        print(\"Falha na importação\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d76d38",
   "metadata": {},
   "source": [
    "### inserir update na tabela produtos os id dos macroprodutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "597f02d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funções importadas com sucesso!\n",
      "✓ Conexão estabelecida com sucesso\n",
      "✓ Macrogrupo 1: 256 registros atualizados\n",
      "✓ Macrogrupo 2: 228 registros atualizados\n",
      "✓ Macrogrupo 3: 70 registros atualizados\n",
      "✓ Macrogrupo 4: 198 registros atualizados\n",
      "✓ Macrogrupo 5: 96 registros atualizados\n",
      "✓ Macrogrupo 6: 30 registros atualizados\n",
      "✓ Macrogrupo 7: 36 registros atualizados\n",
      "✓ Macrogrupo 8: 194 registros atualizados\n",
      "✓ Macrogrupo 9: 128 registros atualizados\n",
      "✓ Macrogrupo 10: 62 registros atualizados\n",
      "✓ Macrogrupo 11: 96 registros atualizados\n",
      "✓ Macrogrupo 12: 180 registros atualizados\n",
      "✓ Conexão encerrada com sucesso\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Adiciona o caminho absoluto da pasta _9_funcoes ao Python\n",
    "caminho_funcoes = r'C:\\digital college\\DA18\\PYTHON\\Projeto_Unidade_3\\_9_funcoes'\n",
    "sys.path.append(caminho_funcoes)\n",
    "\n",
    "# Agora os imports devem funcionar\n",
    "from conectar_banco import conectar_banco\n",
    "from atualizar_macrogrupo import atualizar_macrogrupo\n",
    "from fechar_conexao import fechar_conexao\n",
    "\n",
    "print(\"Funções importadas com sucesso!\")\n",
    "def main():\n",
    "    # Conecta ao banco\n",
    "    conexao, cursor = conectar_banco()\n",
    "    if not conexao:\n",
    "        return\n",
    "\n",
    "    # Dados manuais (você edita aqui)\n",
    "    categorias = [(['MURUMURU%','PINHÃO%','GUARANÁ%', 'MACAÚBA%','MAMONA%','CANA%','MACAÚBA','COCO%','PESSEGO%','PÊSSEGO%','LICURI%','MURICI%','ABACATE%','GOIABA%','GRAVIOLA%',\n",
    "                'ACEROLA%','CAJU%', 'AÇAÍ%','BURITI%', 'ABACAXI%','BANANA%','BARU%','JUÇARA%','LARANJA%','MAÇÃ%','LIMÃO%','JACA%',\n",
    "                'MAMÃO%', 'MANGA%', 'MARACUJÁ%','PEQUI%','PINHA%','TANGERINA%', 'UMBU%', 'UVA%'], 1),\n",
    "                (['FAVA%','CANOLA%','CENTEIO%','ARROZ%','AVEIA%','CEVADA%','FEIJÃO%','MILHO%','FLOCOS%','MILHETO%','TRITICALE%','TRIGO%',\n",
    "                'SOJA%','AVEIA%','CEVADA%','SORGO%'], 2),\n",
    "                (['BATATA%','MANDIOCA%','CARÁ%','INHAME%','MANDIOCA%','RAIZ%'],3),\n",
    "                (['BEZERRO%','NOVILHO%','BOI%','CARNE%','FRANGO%','SUÍNO%','BAGRE%','CAÇÃO%','VACA%','CAPRINO%','SARDA%', 'SARDINHA%', 'AMARELA%',\n",
    "                  'TAMBAQU%','PACU%','JARAQUI%','MATRINX%','PEROÁ%','%AMARELA%','CURIMATÃ%','DOURADO%','PIAU%','CORVINA%','PESCADINHA%','BADEJO%','CAMARÃO%','PIRARUCU%'], 4),\n",
    "                (['LEITE%','QUEIJO%','OVOS%','IOGURTE%','%LACTEA%'],5),\n",
    "                (['ÓLEO%','AZEITE%','OLEO%'],6),\n",
    "                (['AÇÚCAR%', 'AÇUCAR%','MEL%','SAL%'], 7),                # Açúcares\n",
    "                (['FARINHA%','FUBÁ%', 'FÉCULA%','POLVILHO%','MASSA%'], 8),   # Farinhas\n",
    "                (['CEBOLA%','PUPUNHA%', 'TOMATE%','ALHO%','PIMENTÃO%','QUIABO%','PEPINO%','ABÓBORA%','ABOBRINHA%','ALFACE%','BERINJELA%','MAXIXE%','CEBOLINHA%',\n",
    "                  'CHUCHU%','ERVA%','COENTRO%','CHEIRO VERDE%','COUVE%','RÚCULA%','PIMENTA DE CHEIRO%','PIMENTA%'], 9),                 # Hortaliças e Legumes\n",
    "                (['CACAU%','ALGOD%','CASTANHA%','AMÊNDOA%','AMENDOI%','GIRASSOL%','SEMENTE%', 'CARO%'], 10),                     # Castanhas e Sementes\n",
    "                (['POLPA%','CAFÉ%', 'EXTRATO%', 'SUCO%','BEBIDA%','CANJICA%'], 11),               # Bebidas e Extratos\n",
    "                (['LATEX%','LÁTEX%','CASULO%','JUTA%','PÓ%','PIAÇAVA%','SISAL%','UBYFOL%','CAL%','BORRACHA%','CERA%',\n",
    "                'FIBRA%','FARELO%','PHOSMET%','10-30-15%','ALUGUEL%','DIARISTA%','ENERGIA%','SACARIA%','MACARRÃO%','BOLO%','PÃO%',\n",
    "                'ADMINISTRADOR%','ANÁLISE%','MOTONIVELADORA%','MARTELETE%', 'SALÁRIO%','TIGER%','TERRA%','SIRIUS%','NOMINEE%','NATIVO%',\n",
    "                'APROACH%','INCRÍVEL%','IRRIGAÇÃO%','KIFIX%','%M2%',], 12)                #Outros\n",
    "                ]\n",
    "\n",
    "    # Processa cada categoria\n",
    "    for padroes, id_grupo in categorias:\n",
    "        atualizar_macrogrupo(conexao, cursor, padroes, id_grupo)\n",
    "\n",
    "    # Fecha conexão\n",
    "    fechar_conexao(conexao, cursor)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a192de8",
   "metadata": {},
   "source": [
    "### Inserir data na dim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2091792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Conexão estabelecida com sucesso\n",
      "✓ Conexão encerrada com sucesso\n",
      "Sucesso!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import psycopg2\n",
    "# Adiciona o caminho absoluto da pasta _9_funcoes ao Python\n",
    "caminho_funcoes = r'C:\\digital college\\DA18\\PYTHON\\Projeto_Unidade_3\\_9_funcoes'\n",
    "sys.path.append(caminho_funcoes)\n",
    "\n",
    "# Agora os imports devem funcionar\n",
    "from conectar_banco import conectar_banco\n",
    "from atualizar_macrogrupo import atualizar_macrogrupo\n",
    "from fechar_conexao import fechar_conexao\n",
    "\n",
    "# Dados dos meses em português\n",
    "meses_pt = [\n",
    "    'Janeiro', 'Fevereiro', 'Março', 'Abril',\n",
    "    'Maio', 'Junho', 'Julho', 'Agosto',\n",
    "    'Setembro', 'Outubro', 'Novembro', 'Dezembro'\n",
    "]\n",
    "\n",
    "# Abrir o CSV\n",
    "def importar_nivel_comercializacao():\n",
    "    conexao, cursor = conectar_banco()\n",
    "    if not conexao:\n",
    "        return False\n",
    "    try:\n",
    "        # Gerar e inserir dados de 2014 a 2023\n",
    "        for ano in range(2014, 2024):\n",
    "            for mes_num in range(1, 13):\n",
    "                ano_mes = ano * 100 + mes_num\n",
    "                mes = meses_pt[mes_num - 1]\n",
    "                \n",
    "                # Comando SQL para inserção\n",
    "                insert_query = (\"\"\"\n",
    "                    INSERT INTO datawarehouse.dim_data (ano_mes, mes, ano)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                \"\"\")\n",
    "                try:\n",
    "                    cursor.execute(insert_query, (ano_mes, mes, ano))\n",
    "                    conexao.commit()\n",
    "                except psycopg2.IntegrityError:\n",
    "                    conexao.rollback()  # Caso o registro já exista\n",
    "                    print(f\"Registro {ano_mes} já existe. Pulando...\")\n",
    "                \n",
    "        return True  # Retorna True apenas depois de processar todos os anos e meses\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro: {e}\")\n",
    "        conexao.rollback()\n",
    "        return False\n",
    "    finally:\n",
    "        fechar_conexao(conexao, cursor)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if importar_nivel_comercializacao():\n",
    "        print(\"Sucesso!\")\n",
    "    else:\n",
    "        print(\"Falha na importação\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25daaed0",
   "metadata": {},
   "source": [
    "### Inserir dimensão região"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebbffed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Conexão estabelecida com sucesso\n",
      "✓ Conexão encerrada com sucesso\n",
      "Regiões importadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import psycopg2\n",
    "\n",
    "# Adiciona o caminho absoluto da pasta _9_funcoes ao Python\n",
    "caminho_funcoes = r'C:\\digital college\\DA18\\PYTHON\\Projeto_Unidade_3\\_9_funcoes'\n",
    "sys.path.append(caminho_funcoes)\n",
    "\n",
    "from conectar_banco import conectar_banco\n",
    "from fechar_conexao import fechar_conexao\n",
    "\n",
    "def importar_regioes():\n",
    "    conexao, cursor = conectar_banco()\n",
    "    if not conexao:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Definindo as regiões do Brasil\n",
    "        regioes = [\n",
    "            {'nome': 'Norte', 'sigla': 'N'},\n",
    "            {'nome': 'Nordeste', 'sigla': 'NE'},\n",
    "            {'nome': 'Centro-Oeste', 'sigla': 'CO'},\n",
    "            {'nome': 'Sudeste', 'sigla': 'SE'},\n",
    "            {'nome': 'Sul', 'sigla': 'S'}\n",
    "        ]\n",
    "        \n",
    "        # Comando SQL para criação da tabela (caso não exista)\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS datawarehouse.dim_regiao (\n",
    "            id_regiao SERIAL PRIMARY KEY,\n",
    "            nome_regiao VARCHAR(50) NOT NULL,\n",
    "            sigla_regiao VARCHAR(2) NOT NULL,\n",
    "            UNIQUE(nome_regiao, sigla_regiao)\n",
    "        )\n",
    "        \"\"\"\n",
    "        cursor.execute(create_table_query)\n",
    "        conexao.commit()\n",
    "        \n",
    "        # Inserindo cada região\n",
    "        for regiao in regioes:\n",
    "            insert_query = \"\"\"\n",
    "            INSERT INTO datawarehouse.dim_regiao (nome_regiao, sigla_regiao)\n",
    "            VALUES (%s, %s)\n",
    "            \"\"\"\n",
    "            cursor.execute(insert_query, (regiao['nome'], regiao['sigla']))\n",
    "        \n",
    "        conexao.commit()\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro: {e}\")\n",
    "        conexao.rollback()\n",
    "        return False\n",
    "    finally:\n",
    "        fechar_conexao(conexao, cursor)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if importar_regioes():\n",
    "        print(\"Regiões importadas com sucesso!\")\n",
    "    else:\n",
    "        print(\"Falha na importação das regiões\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaacf25a",
   "metadata": {},
   "source": [
    "### alter table na dim_estado com fk de regiao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fce576c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Conexão estabelecida com sucesso\n",
      "✓ Coluna id_regiao e FOREIGN KEY adicionadas com sucesso\n",
      "Atualizando regiões para cada estado...\n",
      "Atualizado AC para região Norte\n",
      "Atualizado AM para região Norte\n",
      "Atualizado AP para região Norte\n",
      "Atualizado PA para região Norte\n",
      "Atualizado RO para região Norte\n",
      "Atualizado RR para região Norte\n",
      "Atualizado TO para região Norte\n",
      "Atualizado AL para região Nordeste\n",
      "Atualizado BA para região Nordeste\n",
      "Atualizado CE para região Nordeste\n",
      "Atualizado MA para região Nordeste\n",
      "Atualizado PB para região Nordeste\n",
      "Atualizado PE para região Nordeste\n",
      "Atualizado PI para região Nordeste\n",
      "Atualizado RN para região Nordeste\n",
      "Atualizado SE para região Nordeste\n",
      "Atualizado DF para região Centro-Oeste\n",
      "Atualizado GO para região Centro-Oeste\n",
      "Atualizado MT para região Centro-Oeste\n",
      "Atualizado MS para região Centro-Oeste\n",
      "Atualizado ES para região Sudeste\n",
      "Atualizado MG para região Sudeste\n",
      "Atualizado RJ para região Sudeste\n",
      "Atualizado SP para região Sudeste\n",
      "Atualizado PR para região Sul\n",
      "Atualizado RS para região Sul\n",
      "Atualizado SC para região Sul\n",
      "✓ Atualização de regiões concluída\n",
      "Operação concluída com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# database/alter_table_dim_estados.py\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import psycopg2\n",
    "\n",
    "# Adiciona o caminho absoluto da pasta _9_funcoes ao Python\n",
    "caminho_funcoes = r'C:\\digital college\\DA18\\PYTHON\\Projeto_Unidade_3\\_9_funcoes'\n",
    "sys.path.append(caminho_funcoes)\n",
    "\n",
    "from conectar_banco import conectar_banco\n",
    "from fechar_conexao import fechar_conexao\n",
    "\n",
    "def adicionar_fk_regiao():\n",
    "    \"\"\"\n",
    "    Adiciona a coluna id_regiao e a foreign key para dim_regiao na tabela dim_estados\n",
    "    \"\"\"\n",
    "    conexao, cursor = conectar_banco()\n",
    "    if not conexao:\n",
    "        print(\"✗ Falha na conexão com o banco de dados\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Passo 1: Adicionar a coluna id_regiao se não existir\n",
    "        cursor.execute(\"\"\"\n",
    "            ALTER TABLE datawarehouse.dim_estados\n",
    "            ADD COLUMN IF NOT EXISTS id_regiao INTEGER\n",
    "        \"\"\")\n",
    "        \n",
    "        # Passo 2: Criar a foreign key constraint\n",
    "        cursor.execute(\"\"\"\n",
    "            ALTER TABLE datawarehouse.dim_estados\n",
    "            ADD CONSTRAINT fk_estado_regiao\n",
    "            FOREIGN KEY (id_regiao)\n",
    "            REFERENCES datawarehouse.dim_regiao(id_regiao)\n",
    "            ON DELETE SET NULL\n",
    "        \"\"\")\n",
    "        \n",
    "        conexao.commit()\n",
    "        print(\"✓ Coluna id_regiao e FOREIGN KEY adicionadas com sucesso\")\n",
    "        \n",
    "        # Passo 3: Atualizar os valores de id_regiao para cada estado\n",
    "        print(\"Atualizando regiões para cada estado...\")\n",
    "        \n",
    "        # Mapeamento de estados para regiões (siglas)\n",
    "        estados_regioes = {\n",
    "            'Norte': ['AC', 'AM', 'AP', 'PA', 'RO', 'RR', 'TO'],\n",
    "            'Nordeste': ['AL', 'BA', 'CE', 'MA', 'PB', 'PE', 'PI', 'RN', 'SE'],\n",
    "            'Centro-Oeste': ['DF', 'GO', 'MT', 'MS'],\n",
    "            'Sudeste': ['ES', 'MG', 'RJ', 'SP'],\n",
    "            'Sul': ['PR', 'RS', 'SC']\n",
    "        }\n",
    "        \n",
    "        for regiao, estados in estados_regioes.items():\n",
    "            for uf in estados:\n",
    "                cursor.execute(\"\"\"\n",
    "                    UPDATE datawarehouse.dim_estados e\n",
    "                    SET id_regiao = r.id_regiao\n",
    "                    FROM datawarehouse.dim_regiao r\n",
    "                    WHERE e.estado = %s\n",
    "                    AND r.nome_regiao = %s\n",
    "                \"\"\", (uf, regiao))\n",
    "                \n",
    "                print(f\"Atualizado {uf} para região {regiao}\")\n",
    "        \n",
    "        conexao.commit()\n",
    "        print(\"✓ Atualização de regiões concluída\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        conexao.rollback()\n",
    "        print(f\"✗ Erro durante a execução: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        if conexao:\n",
    "            conexao.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if adicionar_fk_regiao():\n",
    "        print(\"Operação concluída com sucesso!\")\n",
    "    else:\n",
    "        print(\"Falha na operação\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
